{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2TtFJBLOvq09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-06-16 21:45:48.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.core.appconfig\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mLoad DotEnv: True\u001b[0m\n",
            "/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from hcmus.core import appconfig\n",
        "from hcmus.utils import viz_utils\n",
        "from hcmus.lbs import LabelStudioConnector\n",
        "from hcmus.data import CroppedObjectClassificationDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "experiment_name = \"/PrototypicalNetwork\"\n",
        "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "experiment_id = None\n",
        "if not experiment:\n",
        "    experiment_id = mlflow.create_experiment(experiment_name)\n",
        "else:\n",
        "    experiment_id = experiment.experiment_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "accepted_labels = \"\"\"\n",
        "8934804026817-nuoc-tuong-maggi-dau-nanh-thanh-diu-chai-700ml\n",
        "8934804020402-nuoc-tuong-maggi-dau-nanh-dam-dac-700ml\n",
        "8936048470524-mi-tom-3-mien-gold-vi-bo-ham-rau-thom-75g\n",
        "8934822201272-bia-heineken-silver-lon-250ml\n",
        "5054563022592-kem-danh-rang-sensodyne-giam-e-buotlam-sang-rang-100g\n",
        "8934868166344-nuoc-rua-tay-lifebouy-450ml\n",
        "8934707029182-hat-nem-knorr-thit-than-xuong-ong-va-tuy-900g\n",
        "8934822361211-bia-heineken-khong-con-lon-330ml\n",
        "8850006932346-kem-danh-rang-colgate-maxfresh-huong-tra-xanh-225g-+-ban-chai-long-to\n",
        "8850006932322-kem-danh-rang-colgate-maxfresh-huong-bac-ha-225g-+-ban-chai-long-to\n",
        "6920354827792-kem-danh-rang-colgate-maxfresh-tinh-chat-than-tre-225g-+-ban-chai-long-to\n",
        "8936136163314-nuoc-mam-nam-ngu-3-trong-1-750ml\n",
        "8934563198152-mi-hao-hao-chay-vi-rau-nam-74gr\n",
        "8935049501503-nuoc-ngot-coca-cola-vi-nguyen-ban-lon-320ml\n",
        "8936048470036-mi-3-mien-mi-chay-la-da-65g-(goi)\n",
        "8935001215028-tra-tea-break-milk-350ml\n",
        "8935006532755-kem-rua-mat-acnes-vitamin-lam-sang-da,-mo-seo-tham-50g\n",
        "8935018801641-khan-bep-da-nang-pulppy-classic-2-lop-loc-2-cuon\n",
        "8935024123287-ca-phe-sua-hoa-tan-g7-3in1-hop-336g-(16g-x-21-goi)\n",
        "8935006538634-dau-tay-trang-hada-labo-sach-sau-duong-am-toi-uu-200ml\n",
        "8934840000093-nuoc-khoang-chanh-lemona-chai-500ml\n",
        "8997035601321-nuoc-uong-bu-dien-giai-bo-sung-ion-pocari-sweat-chai-900ml\n",
        "4897036693162-nuoc-tang-luc-monster-mango-loco-355ml\n",
        "809939073648-soda-sua-huong-vi-chuoi-milkis-banana\n",
        "8934804038131-tra-hoa-qua-nestea-hoa-tan-hop-144g-12-goi-x-12g\n",
        "8936048471248-mi-tom-chua-cay-dac-biet-3-mien-gold-goi-75g\n",
        "8934804027333-tra-chanh-nestea-hoa-tan-hop-195g-15-goi-x-13g\n",
        "8936010530881-tra-chanh-cozy-hoa-tan-hop-240g-16-goi-x-15g\n",
        "8935049510604-nuoc-ngot-sprite-chai-320ml\n",
        "8934588672118-nuoc-ngot-pepsi-khong-calo-vi-chanh-320ml\n",
        "8935049501572-nuoc-ngot-fanta-vi-cam-lon-320ml\n",
        "8935049500445-nuoc-ngot-fanta-chai-1.5l\n",
        "8936721790017-nuoc-loc-th-true-water-chai-500ml\n",
        "8935049501718-nuoc-ngot-sprite-lon-320ml\n",
        "8936193070013-tra-xanh-khong-do-500ml\n",
        "8935137601122-tra-xanh-thai-nguyen-100g\n",
        "8934564600883-tra-den-c2-vi-dua-luoi-chai-455ml\n",
        "8935001214274-tra-bi-dao-wonderfarm-lon-310ml\n",
        "8934588870552-tra-olong-teaplus-450ml\n",
        "6920354836930-kem-danh-rang-colgate-optic-white-cong-nghe-sac-tim-100g\n",
        "8935049501374-nuoc-ngot-cocacola-vi-nguyen-ban-chai-600ml\n",
        "8935039570700-ca-phe-sua-robusta-birdy-lon-170ml\n",
        "8934673701402-nuoc-dao-necta-vinamilk-hop-1l\n",
        "8935005801012-nuoc-loc-lavie-chai-1-5l\n",
        "8936079140021-ca-phe-sua-highland-coffee-lon-185ml\n",
        "8934588640445-ca-phe-sua-boss-lon-180ml\n",
        "8934683008614-ca-phe-sua-vinacafe-3-in-1-gold-tui-480g-24-goi-tui\n",
        "8934683008867-nuoc-tang-luc-wake-up-247-vi-ca-phe-330ml\n",
        "8935328600156-tra-xanh-tui-loc-phuc-long-2g-x-hop-25-goi\n",
        "4902430805322-nuoc-rua-tay-diet-khuan-safeguard-trang-tinh-khiet-450ml\n",
        "8936156730718-nuoc-xa-vai-blue-dam-dac-huong-thanh-xuan-tui-3.2l\n",
        "8934868166825-dau-goi-sunsilk-natural-duong-ngan-gay-rung-650g\n",
        "8934804040523-tra-vai-va-huong-hoa-lai-nestea-hoa-tan-hop-144g-12-goi-x-12g\n",
        "8934822801335-bia-tiger-crystal-4-6-phan-tram-lon-330ml\n",
        "8934868156871-dau-xa-sunsilk-mem-muot-dieu-ky-320g\n",
        "8936010530713-tra-dao-cozy-hoa-tan-hop-16-goi-x-15g\n",
        "8934868171850-nuoc-lau-kinh-sunlight-sieu-nhanh-sach-trong-suot-chai-520ml\n",
        "8850228003541-nuoc-tang-luc-warrior-huong-dau-chai-330ml\n",
        "8936193070075-nuoc-tang-luc-number-1-chai-330ml\n",
        "8934588012112-nuoc-ngot-pepsi-cola-320ml\n",
        "8936013254951-nuoc-rua-kinh-gift-540ml\n",
        "8934868190394-nuoc-giat-comfort-huong-hoa-anh-dao-va-dao-tuoi-tui-3kg\n",
        "3068320055008-nuoc-loc-evivan-chai-500ml\n",
        "8936127794206-nuoc-uong-sua-trai-cay-th-true-juice-milk-huong-viet-quat-300ml\n",
        "8935049511038-sua-trai-cay-nutriboost-cam-chai-1l\n",
        "8934673573399-sua-tuoi-tiet-trung-co-duong,-100%-sua-tuoivinamilk-(1lit).\n",
        "3760128640607-sua-tuoi-tiet-trung-promess-nguyen-kem-hop-1l\n",
        "8934822212339-bia-heineken-lon-cao-330ml\n",
        "8801382123446-nuoc-gao-han-quoc-loai-500ml\n",
        "8936036201604-bia-hoegaarden-rosee-chai-248ml\n",
        "8934692090013-bia-1664-blanc-5%-abv-chai-330ml\n",
        "8934868166870-dau-goi-sunsilk-ong-muot-rang-ngoi-chai-650g\n",
        "8934588233074-nuoc-tang-luc-sting-vi-dau-tay-do-330ml\n",
        "8934822431211-bia-tiger-soju-infused-lager-wonder-melon-vi-dua-luoi-lon-330ml\n",
        "8934822112332-bia-tiger-lon-cao-330ml-lon\n",
        "8934868180470-dau-goi-dove-biotin-ngan-gay-rung-toc-880g\n",
        "8935024170519-ca-phe-trung-nguyen-legend-classic-hop-357g-17g-x-21-goi\n",
        "8934868166351-nuoc-rua-tay-lifebuoy-matcha-va-lo-hoichai-450g\n",
        "8936191270057-ca-phe-cappuccino-dua-just-viet-hop-hop-10-goi-x-17g\n",
        "8934868166924-dau-goi-sunsilk-mem-muot-dieu-ky-chai-650g\n",
        "8934804028064-ca-phe-hoa-tan-nescafe-3in1-vi-nguyen-ban-tui-782g-(17g-x-46-goi)\n",
        "8936122200276-ca-phe-mr.brown-blue-mountain-240ml\n",
        "8934563122201-mi-hao-hao-vi-tom-chua-cay-goi-100g\n",
        "8935136865709-sua-tam-purite-duong-da-mem-min-huong-hoa-hong-rose-chai-850ml\n",
        "8934822451295-nuoc-trai-cay-len-men-strongbow-vi-thom-luu-3.5%-lon-330ml\n",
        "8934868170990-nuoc-rua-tay-lifebuoy-vitamin-sua-duong-am-tui-1kg\n",
        "8936094291005-bia-budweiser-5-lon-330ml\n",
        "8934822121297-nuoc-trai-cay-len-men-strongbow-red-beries-4.5%-abv-lon-320ml\n",
        "8934822111298-nuoc-trai-cay-len-men-strongbow-gold-apple-4-5-abv-lon-320ml\n",
        "8935049501190-nuoc-tra-fuze-tea-vi-chanh-sa-450ml\n",
        "8936199810026-cafe-the-coffee-house-sua-da-22gx10-goi-(hop)\n",
        "8888589308920-tra-bi-dao-winter-melon-jj-lon-300ml\n",
        "8934673101097-sua-tuoi-tiet-trung-tiet-trung-vinamilk-khong-duong-bich-220ml\n",
        "8934563183158-mi-hao-hao-sa-te-hanh-tim-75g\n",
        "8936048470012-mi-3-mien-tom-chua-cay-65g\n",
        "8934683009925-ca-phe-sua-da-vinacafe-chat-hop-10-goi-24g\n",
        "8850228007617-nuoc-tang-luc-redbull-250ml\n",
        "8934563651138-mi-hao-hao,-vi-tom-chua-cayacecook,-coc-(67g)\n",
        "8934588063060-nuoc-loc-aquafina-chai-1-5l\n",
        "8935049510857-nuoc-loc-dasani-chai-1.5l\"\"\"\n",
        "accepted_labels = accepted_labels.splitlines()\n",
        "accepted_labels = [x for x in accepted_labels if len(x) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HJ-srbQqvtn8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-06-16 21:45:50.824\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m144\u001b[0m - \u001b[33m\u001b[1mPage size is too large, only 3308 tasks available.\u001b[0m\n",
            "\u001b[32m2025-06-16 21:45:50.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mNew `page_to` applied: 34\u001b[0m\n",
            "Loading tasks: 100%|██████████| 34/34 [00:09<00:00,  3.69it/s]\n",
            "Downloading images: 100%|██████████| 3308/3308 [00:05<00:00, 597.83it/s] \n",
            "\u001b[32m2025-06-16 21:46:05.661\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m144\u001b[0m - \u001b[33m\u001b[1mPage size is too large, only 355 tasks available.\u001b[0m\n",
            "\u001b[32m2025-06-16 21:46:05.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mNew `page_to` applied: 4\u001b[0m\n",
            "Loading tasks: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]\n",
            "Downloading images: 100%|██████████| 355/355 [00:00<00:00, 1786.05it/s]\n",
            "\u001b[32m2025-06-16 21:46:08.636\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m144\u001b[0m - \u001b[33m\u001b[1mPage size is too large, only 82 tasks available.\u001b[0m\n",
            "\u001b[32m2025-06-16 21:46:08.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mNew `page_to` applied: 1\u001b[0m\n",
            "Loading tasks: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
            "Downloading images: 100%|██████████| 82/82 [00:00<00:00, 1046.55it/s]\n"
          ]
        }
      ],
      "source": [
        "splits = {}\n",
        "for split_name in [\"train\", \"test\", \"val\"]:\n",
        "    lsb_connector = LabelStudioConnector(\n",
        "        url=appconfig.LABEL_STUDIO_URL,\n",
        "        api_key=appconfig.LABEL_STUDIO_API_KEY,\n",
        "        project_id=appconfig.LABEL_STUDIO_PROJECT_MAPPING[split_name],\n",
        "        temp_dir=appconfig.LABEL_STUDIO_TEMP_DIR\n",
        "    )\n",
        "\n",
        "    tasks = lsb_connector.get_tasks()\n",
        "    labels = lsb_connector.extract_labels(tasks)\n",
        "    dataset = lsb_connector.download_dataset(tasks, labels)\n",
        "    dataset = lsb_connector.transform_labels(dataset, labels, accepted_labels)\n",
        "    splits[split_name] = dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(90),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(\n",
        "    #     mean=[0.485, 0.456, 0.406],\n",
        "    #     std=[0.229, 0.224, 0.225]\n",
        "    # )\n",
        "])\n",
        "\n",
        "transform_basic = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(\n",
        "    #     mean=[0.485, 0.456, 0.406],\n",
        "    #     std=[0.229, 0.224, 0.225]\n",
        "    # )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-06-16 21:46:09.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.data._torch_dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mAuto infer `label2idx` mapping, mapping length: 90.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from easyfsl.samplers import TaskSampler\n",
        "from hcmus.data import CroppedFewShotDataset\n",
        "device = \"cpu\"\n",
        "skip_labels = [\n",
        "    \"object\",\n",
        "    \"8936136163314-nuoc-mam-nam-ngu-3-trong-1-750ml\",\n",
        "    \"8936079140021-ca-phe-sua-highland-coffee-lon-185ml\",\n",
        "    \"8936048470012-mi-3-mien-tom-chua-cay-65g\",\n",
        "    \"8934822111298-nuoc-trai-cay-len-men-strongbow-gold-apple-4-5-abv-lon-320ml\",\n",
        "    \"8936036201604-bia-hoegaarden-rosee-chai-248ml\",\n",
        "    \"8934673101097-sua-tuoi-tiet-trung-tiet-trung-vinamilk-khong-duong-bich-220ml\",\n",
        "    \"8801382123446-nuoc-gao-han-quoc-loai-500ml\",\n",
        "    \"5054563022592-kem-danh-rang-sensodyne-giam-e-buotlam-sang-rang-100g\",\n",
        "    \"8850006932322-kem-danh-rang-colgate-maxfresh-huong-bac-ha-225g-+-ban-chai-long-to\",\n",
        "]\n",
        "train_dataset = CroppedFewShotDataset(splits[\"train\"], skip_labels=skip_labels, transforms=transform_train)\n",
        "val_dataset = CroppedFewShotDataset(splits[\"val\"], label2idx=train_dataset.label2idx, transforms=transform_basic, is_test=True)\n",
        "\n",
        "epoch = 64\n",
        "n_classes = len(train_dataset.label2idx)\n",
        "n_way = 5\n",
        "n_shot = 5\n",
        "n_query = 10\n",
        "n_tasks = 512\n",
        "train_sampler = TaskSampler(\n",
        "    dataset=train_dataset,\n",
        "    n_way=n_way,\n",
        "    n_shot=n_shot,\n",
        "    n_query=n_query,\n",
        "    n_tasks=n_tasks\n",
        ")\n",
        "val_sampler = TaskSampler(\n",
        "    dataset=train_dataset,\n",
        "    n_way=n_classes,\n",
        "    n_shot=n_shot,\n",
        "    n_query=0,\n",
        "    n_tasks=n_tasks\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_sampler=train_sampler,\n",
        "    collate_fn=train_sampler.episodic_collate_fn\n",
        ")\n",
        "val_support_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_sampler=val_sampler,\n",
        "    collate_fn=val_sampler.episodic_collate_fn\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from clip import clip\n",
        "from hcmus.models.prototype import setup_training\n",
        "clip.available_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "__init__() got an unexpected keyword argument 'feature_dim'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m backbone_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViT-B/16\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m freeze_backbone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model, trainer, optimizer, scheduler \u001b[38;5;241m=\u001b[39m \u001b[43msetup_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreeze_backbone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m val_support_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(val_support_dataloader)\n\u001b[1;32m      5\u001b[0m query_images, query_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(val_dataloader))\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/src/hcmus/models/prototype.py:342\u001b[0m, in \u001b[0;36msetup_training\u001b[0;34m(backbone_name, freeze_backbone)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup_training\u001b[39m(backbone_name, freeze_backbone: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    339\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    Setup training configuration\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreeze_backbone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m OpenWorldTrainer(model)\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# Optimizer\u001b[39;00m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/src/hcmus/models/prototype.py:328\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(backbone_name, freeze_backbone)\u001b[0m\n\u001b[1;32m    325\u001b[0m backbone \u001b[38;5;241m=\u001b[39m CLIPViTBackbone(backbone_name, freeze_backbone\u001b[38;5;241m=\u001b[39mfreeze_backbone)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# Create open-world prototypical network\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mOpenWorldPrototypicalNetwork\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43munknown_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cosine_similarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    334\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'feature_dim'"
          ]
        }
      ],
      "source": [
        "backbone_name = \"ViT-B/16\"\n",
        "freeze_backbone = False\n",
        "model, trainer, optimizer, scheduler = setup_training(backbone_name, freeze_backbone)\n",
        "val_support_iter = iter(val_support_dataloader)\n",
        "query_images, query_labels = next(iter(val_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training...:  25%|██▌       | 25/100 [12:45<38:16, 30.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run prototypical_clip_vit at: http://jimica.ddns.net:5050/#/experiments/990966814347092903/runs/8ee0647761b24ff1a14bc94c97d261fa\n",
            "🧪 View experiment at: http://jimica.ddns.net:5050/#/experiments/990966814347092903\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m support_images, support_labels, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(val_support_iter)\n\u001b[1;32m     13\u001b[0m query_images, query_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(val_dataloader))\n\u001b[0;32m---> 14\u001b[0m val_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metrics(val_result, step\u001b[38;5;241m=\u001b[39mstep)\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/src/hcmus/models/prototype.py:257\u001b[0m, in \u001b[0;36mOpenWorldTrainer.evaluate_episode\u001b[0;34m(self, support_images, support_labels, query_images, query_labels, has_unknown)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 257\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Get predictions (including unknown class)\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobabilities\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/src/hcmus/models/prototype.py:125\u001b[0m, in \u001b[0;36mOpenWorldPrototypicalNetwork.forward\u001b[0;34m(self, support_images, support_labels, query_images, return_features)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03mForward pass for few-shot classification with open-world detection\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m support_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m query_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(query_images)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Apply projection head\u001b[39;00m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/src/hcmus/models/prototype.py:33\u001b[0m, in \u001b[0;36mCLIPViTBackbone.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Forward pass through ViT backbone\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        Feature tensor of shape (batch_size, 512)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/clip/model.py:232\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_pre(x)\n\u001b[1;32m    231\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NLD -> LND\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# LND -> NLD\u001b[39;00m\n\u001b[1;32m    235\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(x[:, \u001b[38;5;241m0\u001b[39m, :])\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/clip/model.py:203\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/clip/model.py:190\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 190\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x))\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/clip/model.py:187\u001b[0m, in \u001b[0;36mResidualAttentionBlock.attention\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mattention\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_mask\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/modules/activation.py:1373\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1348\u001b[0m         query,\n\u001b[1;32m   1349\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1371\u001b[0m     )\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1373\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/functional.py:6230\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   6227\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   6228\u001b[0m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6229\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6230\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6232\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   6233\u001b[0m         q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6234\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/torch/nn/functional.py:5614\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   5611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m v:\n\u001b[1;32m   5612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m q \u001b[38;5;129;01mis\u001b[39;00m k:\n\u001b[1;32m   5613\u001b[0m         \u001b[38;5;66;03m# self-attention\u001b[39;00m\n\u001b[0;32m-> 5614\u001b[0m         proj \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5615\u001b[0m         \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[1;32m   5616\u001b[0m         proj \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   5617\u001b[0m             proj\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m3\u001b[39m, E))\n\u001b[1;32m   5618\u001b[0m             \u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5621\u001b[0m             \u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m   5622\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "with mlflow.start_run(experiment_id=experiment_id, run_name=\"prototypical_clip_vit\"):\n",
        "    mlflow.log_params({\n",
        "        \"freeze_backbone\": freeze_backbone\n",
        "    })\n",
        "    for step, episode in tqdm(enumerate(train_dataloader), desc=\"Training...\", total=n_tasks):\n",
        "        support_images, support_labels, query_images, query_labels, unique_labels = episode\n",
        "        train_result = trainer.train_episode(support_images, support_labels, query_images, query_labels, optimizer)\n",
        "        mlflow.log_metrics(train_result, step=step)\n",
        "\n",
        "        support_images, support_labels, _, _, _ = next(val_support_iter)\n",
        "        query_images, query_labels = next(iter(val_dataloader))\n",
        "        val_result = trainer.evaluate_episode(support_images, support_labels, query_images, query_labels, True)\n",
        "        mlflow.log_metrics(val_result, step=step)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
