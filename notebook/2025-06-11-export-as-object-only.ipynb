{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q git+https://github.com/tcstrength/item-identification.git@main timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-15 21:23:45.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.core.appconfig\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mLoad DotEnv: True\u001b[0m\n",
      "/Volumes/Cucumber/Projects/item-identification/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from hcmus.core import appconfig\n",
    "from hcmus.lbs import LabelStudioConnector\n",
    "from hcmus.utils import viz_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_labels = \"\"\"\n",
    "\"\"\"\n",
    "accepted_labels = accepted_labels.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-15 21:23:47.250\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m148\u001b[0m - \u001b[33m\u001b[1mPage size is too large, only 3443 tasks available.\u001b[0m\n",
      "\u001b[32m2025-07-15 21:23:47.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mNew `page_to` applied: 35\u001b[0m\n",
      "Loading tasks: 100%|██████████| 35/35 [00:11<00:00,  3.14it/s]\n",
      "Downloading images: 100%|██████████| 3443/3443 [00:06<00:00, 557.94it/s] \n",
      "\u001b[32m2025-07-15 21:24:04.672\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m148\u001b[0m - \u001b[33m\u001b[1mPage size is too large, only 420 tasks available.\u001b[0m\n",
      "\u001b[32m2025-07-15 21:24:04.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mNew `page_to` applied: 5\u001b[0m\n",
      "Loading tasks: 100%|██████████| 5/5 [00:04<00:00,  1.10it/s]\n",
      "Downloading images: 100%|██████████| 420/420 [00:02<00:00, 193.55it/s]\n",
      "\u001b[32m2025-07-15 21:24:11.461\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m148\u001b[0m - \u001b[33m\u001b[1mPage size is too large, only 309 tasks available.\u001b[0m\n",
      "\u001b[32m2025-07-15 21:24:11.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhcmus.lbs._label_studio_connector\u001b[0m:\u001b[36mget_tasks\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mNew `page_to` applied: 4\u001b[0m\n",
      "Loading tasks: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n",
      "Downloading images: 100%|██████████| 309/309 [00:01<00:00, 175.12it/s]\n"
     ]
    }
   ],
   "source": [
    "splits = {}\n",
    "for split_name in [\"train\", \"test\", \"val\"]:\n",
    "    lsb_connector = LabelStudioConnector(\n",
    "        url=appconfig.LABEL_STUDIO_URL,\n",
    "        api_key=appconfig.LABEL_STUDIO_API_KEY,\n",
    "        project_id=appconfig.LABEL_STUDIO_PROJECT_MAPPING[split_name],\n",
    "        temp_dir=appconfig.LABEL_STUDIO_TEMP_DIR\n",
    "    )\n",
    "\n",
    "    tasks = lsb_connector.get_tasks()\n",
    "    labels = lsb_connector.extract_labels(tasks)\n",
    "    dataset = lsb_connector.download_dataset(tasks, labels)\n",
    "    dataset = [x for x in dataset if x.get(\"target\").get(\"labels\")]\n",
    "    idx2label = {v: k for k, v in labels.items()}\n",
    "    for item in dataset:\n",
    "        new_labels = []\n",
    "        for idx in item.get(\"target\").get(\"labels\"):\n",
    "            label_str = idx2label[idx]\n",
    "            if label_str in accepted_labels:\n",
    "                new_labels.append(idx2label[idx])\n",
    "            else:\n",
    "                # Compatible with SKU110k\n",
    "                new_labels.append(\"object\")\n",
    "        item.get(\"target\")[\"labels\"] = new_labels\n",
    "    splits[split_name] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "def generate_categories(splits):\n",
    "    label_set = set()\n",
    "    for split_data in splits.values():\n",
    "        for item in split_data:\n",
    "            label_set.update(item[\"target\"][\"labels\"])\n",
    "    label_list = sorted(label_set)\n",
    "    return [{\"id\": i + 1, \"name\": label} for i, label in enumerate(label_list)], {\n",
    "        label: i + 1 for i, label in enumerate(label_list)\n",
    "    }\n",
    "\n",
    "def convert_split_to_coco(data, categories_dict, split_name, split_output_dir):\n",
    "    images_dir = os.path.join(split_output_dir, \"images\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "    coco_dict = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [{\"id\": cid, \"name\": name} for name, cid in categories_dict.items()]\n",
    "    }\n",
    "\n",
    "    ann_id = 1\n",
    "    for img_id, item in enumerate(data):\n",
    "        img_path = item[\"image\"]\n",
    "        target = item[\"target\"]\n",
    "        boxes = target[\"boxes\"]\n",
    "        labels = target[\"labels\"]\n",
    "\n",
    "        file_name = os.path.basename(img_path)\n",
    "        dst_path = os.path.join(images_dir, file_name)\n",
    "        shutil.copyfile(img_path, dst_path)\n",
    "\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "        coco_dict[\"images\"].append({\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        for box, label in zip(boxes, labels):\n",
    "            x1, y1, x2, y2 = box\n",
    "            bbox = [x1, y1, x2 - x1, y2 - y1]\n",
    "            area = bbox[2] * bbox[3]\n",
    "\n",
    "            coco_dict[\"annotations\"].append({\n",
    "                \"id\": ann_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": categories_dict[label],\n",
    "                \"bbox\": bbox,\n",
    "                \"area\": area,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            ann_id += 1\n",
    "\n",
    "    # Save JSON in split folder\n",
    "    json_path = os.path.join(split_output_dir, f\"annotations_{split_name}.json\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(coco_dict, f, indent=2)\n",
    "\n",
    "    print(f\"✔ {split_name}: saved {len(data)} images and annotations to {split_output_dir}\")\n",
    "\n",
    "def convert_splits_to_coco(splits, base_output_dir):\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    _, label_to_id = generate_categories(splits)\n",
    "\n",
    "    for split_name, data in splits.items():\n",
    "        split_output_dir = os.path.join(base_output_dir, split_name)\n",
    "        os.makedirs(split_output_dir, exist_ok=True)\n",
    "        convert_split_to_coco(data, label_to_id, split_name, split_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ train: saved 3443 images and annotations to /Volumes/Cucumber/Projects/datasets/curated/hcmus-iid-object/train\n",
      "✔ test: saved 420 images and annotations to /Volumes/Cucumber/Projects/datasets/curated/hcmus-iid-object/test\n",
      "✔ val: saved 309 images and annotations to /Volumes/Cucumber/Projects/datasets/curated/hcmus-iid-object/val\n"
     ]
    }
   ],
   "source": [
    "convert_splits_to_coco(splits, \"/Volumes/Cucumber/Projects/datasets/curated/hcmus-iid-object\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
